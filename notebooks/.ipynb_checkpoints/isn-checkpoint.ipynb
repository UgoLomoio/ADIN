{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ec16e-1b52-4c99-833e-134ba936c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.chdir(\"..\")\n",
    "cwd = os.getcwd()\n",
    "sep = os.sep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed4fa7-52e8-4822-a1e8-f5c1a69d1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e32125-bca0-45fb-a813-4352018ed2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filename = cwd + sep + \"use_case\"+sep+\"data\"+sep+\"bladder_cancer\"+sep+\"gene_expression_data_preprocessed.csv\"\n",
    "output = cwd + sep + \"ouput.png\"\n",
    "expr = pd.read_csv(expr_filename, index_col = 0)\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc133d9-bd81-4b1d-9de5-75e5ef76c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.DataFrame(expr[\"Target\"])\n",
    "expr = expr.drop(\"Target\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6a291-7066-4402-b1c4-ccb722de6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adin import utils \n",
    "isns, interaction_df = utils.create_sparse_isns(expr, th = 0.998)\n",
    "print(f\"Interaction dataframe: {interaction_df}\")\n",
    "isns = torch.stack(isns).to(device)\n",
    "print(isns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bc6c8-590c-493f-861f-bfd129da84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [row[\"feature_1\"]+\"_\"+row[\"feature_2\"] for index, row in interaction_df.iterrows()]\n",
    "# Parse the edges and create node mapping\n",
    "source_nodes, target_nodes, node_mapping = utils.parse_edges(edge_list)\n",
    "# Create edge_index tensor\n",
    "edge_index = utils.create_edge_index(source_nodes, target_nodes)\n",
    "    \n",
    "y = torch.tensor(targets.values).to(device).flatten()\n",
    "edge_index = edge_index.to(device)\n",
    "print(y.shape, edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af648eef-4234-4cd7-9c84-33fa22a6edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "n_graphs = isns.shape[1]\n",
    "patients = list(expr.index)\n",
    "nodes = list(node_mapping.keys())\n",
    "for i in range(n_graphs):\n",
    "    row = expr.values[i, :]\n",
    "    idx_nodes = [i for i, node in enumerate(nodes) if node in expr.columns]\n",
    "    masked_row = row[idx_nodes]\n",
    "    x.append(torch.tensor(masked_row))\n",
    "x = torch.stack(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc0e2c-3ec2-4546-af6e-f689a1f7c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adin.dl import create_torch_geo_data\n",
    "\n",
    "def train_test_split_and_mask(data, node_mapping_rev, train_size = 0.2, isn = False):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        data: torch_geometric.Data object\n",
    "        train_size: float between 0.0 and 1.0, OPTIONAL, default 0.2\n",
    "    \"\"\"\n",
    "    #input \n",
    "    \n",
    "    # Assuming `data.y` contains the labels\n",
    "    num_nodes = data.num_nodes\n",
    "    if train_size < 0.1 or train_size >= 1:\n",
    "       raise Exception(\"Train size {} must be greater (or equal) then 0.1 and lower then 1\".format(train_size))\n",
    "\n",
    "    # Create a boolean mask for training nodes\n",
    "    indices = torch.arange(num_nodes).to(device)\n",
    "    train_indices, test_indices = train_test_split(indices, train_size=train_size, stratify=data.y.cpu())\n",
    "    y = data.y\n",
    "    \n",
    "    #uqs, counts = torch.unique(y, return_counts = True)\n",
    "    #start = int((2/3)*counts[0])\n",
    "    #train_indices = torch.arange(0, start).to(device)\n",
    "    #test_indices = torch.arange(start, num_nodes).to(device)\n",
    "\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
    "    train_mask[train_indices] = True\n",
    "    test_mask[test_indices] = True\n",
    "\n",
    "    data.edge_index = data.edge_index.to(device)\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    if not isn:\n",
    "        train_edgeindex = filter_edge_index(data.edge_index, data.train_mask)\n",
    "        test_edgeindex = filter_edge_index(data.edge_index, data.test_mask)\n",
    "    else:\n",
    "        train_edgeindex = data.edge_index\n",
    "        test_edgeindex = data.edge_index\n",
    "        \n",
    "    train_dataloader = create_torch_geo_data(data.x[data.train_mask], data.y[data.train_mask], train_edgeindex)\n",
    "    test_dataloader = create_torch_geo_data(data.x[data.test_mask], data.y[data.test_mask], test_edgeindex)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "# Filter the edge_index and ensure all edges reference valid nodes in the mask\n",
    "def filter_edge_index(edge_index, mask):\n",
    "    \n",
    "    # Get the indices of valid nodes according to the mask\n",
    "    idx_map = torch.nonzero(mask, as_tuple=True)[0].to(device)\n",
    "    \n",
    "    # Create a mapping from old indices to new indices\n",
    "    node_idx_map = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(idx_map)}\n",
    "\n",
    "    # Filter edge_index to include only valid edges\n",
    "    mask_edge_index = (mask[edge_index[0]] & mask[edge_index[1]]).nonzero(as_tuple=False).to(device).squeeze()\n",
    "    \n",
    "    if mask_edge_index.numel() == 0:\n",
    "        return torch.empty((2, 0), dtype=torch.long).to(device)  # No valid edges\n",
    "\n",
    "    # Filter and remap edge_index\n",
    "    filtered_edge_index = edge_index[:, mask_edge_index]\n",
    "    filtered_edge_index = torch.tensor([[node_idx_map.get(int(i), -1) for i in edge] for edge in filtered_edge_index.t()], dtype=torch.long).to(device).t()\n",
    "\n",
    "    # Remove edges with -1 index due to remapping issues\n",
    "    valid_edges = filtered_edge_index.min(dim=0).values >= 0\n",
    "    filtered_edge_index = filtered_edge_index[:, valid_edges]\n",
    "\n",
    "    return filtered_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbf9a7-a2f1-43a7-9f0b-f737d0a03f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adin import gaan_config, dl\n",
    "\n",
    "uqs, counts = torch.unique(y, return_counts = True)\n",
    "dict_counts = {}\n",
    "for uq, count in zip(uqs, counts):\n",
    "    dict_counts[uq.item()] = count.item()\n",
    "contamination = (dict_counts[1]/(dict_counts[0] + dict_counts[1]))*0.5\n",
    "gpu = 0 if torch.cuda.is_available() else -1\n",
    "gaan_params = gaan_config.GAAN_config(noise_dim=64, hid_dim=128, num_layers=2, dropout=0.3, contamination=contamination, lr = 0.00005, epoch = 200, gpu = -1, batch_size=1, verbose = 1, isn = True, th = 0.93)\n",
    "\n",
    "x = x.cpu()\n",
    "y = y.cpu()\n",
    "edge_index = edge_index.cpu()\n",
    "mydataloader = dl.create_torch_geo_data(x, y, edge_index)\n",
    "node_mapping_rev = {value: key for key, value in node_mapping.items()}\n",
    "mydataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160319b-a559-419f-bf20-042586126394",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train - Test split\")\n",
    "device = \"cpu\"\n",
    "dataloader_train, dataloader_test = train_test_split_and_mask(mydataloader, node_mapping_rev, train_size = 0.7, isn = True)\n",
    "in_dim = dataloader_train.x.shape[1]\n",
    "dataloader_train.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461b56c-6943-41ec-adf2-5e506a04b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create GAAN model\")\n",
    "model = dl.create_model(in_dim, gaan_params, isn = True)\n",
    "model = model.to(\"cpu\")\n",
    "model = dl.train_gaan(model, dataloader_train)\n",
    "models[\"GAAN_isn\"] = model\n",
    "if \"Temp\" in models.keys():\n",
    "    del models[\"Temp\"]\n",
    "df_result = dl.create_results_df({\"GAAN_isn\": model}, dataloader_test)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86085b7-d566-4b52-999b-1dd18717d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dataloader_test).cpu()\n",
    "explainer = None\n",
    "explainers[\"GAAN_isn\"] = explainer   \n",
    "y_test = dataloader_test.y.cpu()\n",
    "classes = {0: \"Normal\", 1: \"Anomalous\"}\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "fig_cm = dl.plot_cm(classes, cm, \"GAAN_isn\")\n",
    "fig_roc_test = ml.plot_roc_curve_(y_test, preds)\n",
    "fig_cm.show()\n",
    "fig_roc_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc4460-4453-455d-a249-5fbe41a83a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b5b11-d68f-4e1f-a063-ffe22f2c433f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adin",
   "language": "python",
   "name": "adin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
