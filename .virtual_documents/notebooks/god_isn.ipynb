#!pip install git+https://github.com/GiadaLalli/ISN-tractor


!python --version


import gc
gc.collect()


import torch
import numpy as np
import random

random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
torch.cuda.manual_seed(42)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False


in_colab = False


if in_colab:

  from google.colab import drive
  drive.mount("/content/drive/", force_remount = True)


if in_colab:
  !pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 #-f https://download.pytorch.org/whl/cu121


if in_colab:
  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cpu.html#torch-2.3.0+cu121.html


if in_colab:
  !pip install torch_geometric


if in_colab:
  import locale
  def getpreferredencoding(do_setlocale = True):
      return "UTF-8"
  locale.getpreferredencoding = getpreferredencoding
  !pip install pygod


import torch
torch.__version__


import torch_geometric
print(torch_geometric.typing.WITH_PYG_LIB)


if in_colab:
  %cd "/content/drive/MyDrive/Colab Notebooks/GraphOutlierDetection"


!dir


import os
cwd = os.getcwd()
sep = os.sep
datapath = cwd + sep + "Dataset" + sep
datapath


expr_filename = cwd + sep + "use_case"+sep+"data"+sep+"bladder_cancer"+sep+"gene_expression_data_preprocessed.csv"
output = cwd + sep + "ouput.png"


import pandas as pd

expr = pd.read_csv(expr_filename, index_col = 0)
expr


clinic = pd.DataFrame(expr["Target"])
clinic


expr = expr.drop("Target", axis = 1)
expr


import torch
device = "cuda:0" if torch.cuda.is_available() else "cpu"
device


import torch
import numpy as np

def parse_edges(edge_list):
    source_nodes = []
    target_nodes = []
    node_mapping = {}
    next_index = 0

    for edge in edge_list:
        source, target = edge.split('_')
        #if source == target:
        #    continue
        if source not in node_mapping:
            node_mapping[source] = next_index
            next_index += 1
        if target not in node_mapping:
            node_mapping[target] = next_index
            next_index += 1

        source_nodes.append(node_mapping[source])
        target_nodes.append(node_mapping[target])

    return source_nodes, target_nodes, node_mapping

def create_edge_index(source_nodes, target_nodes):
    edge_list = np.array([source_nodes, target_nodes], dtype=np.int64)
    edge_index = torch.LongTensor(edge_list)
    return edge_index


#!pip install numpy==1.24.1


from isn_tractor import ibisn as it
import numpy as np


import gc 
import isn_tractor as isn

def create_denseisns(expr):
    gc.collect()
    torch.cuda.empty_cache()
    isn_generator = it.dense_isn(expr, device)
    
    isns = []
    for i, isn in enumerate(isn_generator):
        print(i)
        isns.append(isn)
        del isn
        gc.collect()
        torch.cuda.empty_cache()
        break
    return isns


def create_interaction_df(values, genes, th=0.4):
    
    values = torch.from_numpy(values).to(device)
    
    corr = torch.corrcoef(values)

    df = pd.DataFrame([], columns = ["feature_1", "feature_2"])
    idx = 0
    for i in range(corr.shape[0]):
        for j in range(corr.shape[1]):
            if i != j:
                c = corr[i, j]
                if abs(c) >= th:
                    gene1 = genes[i]
                    gene2 = genes[j]
                    df.loc[idx] = [gene1, gene2]
                    idx += 1 
    return df


interaction_df = create_interaction_df(values, genes, th=0.4)
interaction_df


genes = expr.columns
values = expr.values


def create_sparse_isns(expr, th = 0.4): 

    genes = expr.columns
    values = expr.values
    
    interaction_df = create_interaction_df(values, genes, th = th)
    isn_generator = it.sparse_isn(expr, None, interaction_df, "pearson", "average", device)
    
    isns = []
    for i, isn in enumerate(isn_generator):
        if i%100 == 0:
            print(i, isn.shape)
        isns.append(isn)
        del isn
        gc.collect()
        torch.cuda.empty_cache()

    return isns, interaction_df


isns, interaction_df = create_sparse_isns(expr)
isns[0].shape


isns = torch.stack(isns).to(device)
isns = isns.T
isns


isns.shape





from adin import utils, dl, gaan_config


edge_list = [row["feature_1"]+"_"+row["feature_2"] for index, row in interaction_df.iterrows()]
edge_list


# Parse the edges and create node mapping
source_nodes, target_nodes, node_mapping = parse_edges(edge_list)

# Print node mapping for reference
print("Node Mapping:", node_mapping)


# Create edge_index tensor
edge_index = create_edge_index(source_nodes, target_nodes)

print("Edge Index Tensor:")
print(edge_index)


import pygod
from pygod.utils import load_data

x = torch.tensor(isns).to(device)
y = torch.tensor(clinic.values).to(device).flatten()
edge_index = edge_index.to(device)
x.shape, y.shape, edge_index.shape


uqs, counts = torch.unique(y, return_counts = True)
dict_counts = {}
for uq, count in zip(uqs, counts):
    dict_counts[uq.item()] = count.item()
contamination = (dict_counts[1]/(dict_counts[0] + dict_counts[1]))*0.5
contamination


gaan_params = gaan_config.GAAN_config(noise_dim=2,
    hid_dim=4,
    num_layers=4,
    dropout=0.3,
    contamination=contamination,
    lr=0.0005,
    epoch=400,
    gpu=0,
    batch_size=64,
    verbose=1,
    isn = True
)


from sklearn.metrics import confusion_matrix

models = {} 
edges = interaction_df.values
edges = [f"{edge[0]}_{edge[1]}" for edge in edges]
# Parse the edges and create node mapping
source_nodes, target_nodes, node_mapping = utils.parse_edges(edges)
# Create edge_index tensor
edge_index = utils.create_edge_index(source_nodes, target_nodes)
x = isns
y = clinic.values
mydataloader = dl.create_torch_geo_data(x, y, edge_index)
node_mapping_rev = {value: key for key, value in node_mapping.items()}
dataloader_train, dataloader_test = dl.train_test_split_and_mask(mydataloader, node_mapping_rev, train_size = 0.6)
in_dim = dataloader_train.x.shape[1]
model = dl.create_model(in_dim, gaan_params)
model = dl.train_gaan(model, dataloader_train)
models["GAAN"] = model

if "Temp" in models.keys():
    del models["Temp"]


model.eval()
df_result = dl.create_results_df(model, dataloader_test)
df_result


from adin import ml 
from torch_geometric.explain import GNNExplainer, Explainer
preds = model.predict(dataloader_train).cpu()
y_test = dataloader_train.y.cpu()
classes = {0: "Normal", 1: "Anomalous"}
cm = confusion_matrix(y_test, preds)
fig_cm = dl.plot_cm(classes, cm, "GAAN")
fig_roc_test = ml.plot_roc_curve_(y_test, preds)
fig_roc_test.show()


fig_cm.show()


fig_roc_test.show()


from copy import copy
from math import sqrt
from typing import Optional

import torch
from tqdm import tqdm
import networkx as nx
from torch_geometric.nn import MessagePassing
from torch_geometric.data import Data
from torch_geometric.utils import k_hop_subgraph, to_networkx
from torch_geometric.explain.algorithm import GNNExplainer

class GNNGraphExplainer(GNNExplainer):
    
    def __init__(self,model, epochs: int = 100, lr: float = 0.01,
                 num_hops: int = None, return_type: str = 'log_prob',
                 log: bool = True):
        super(GNNGraphExplainer, self).__init__()
                
        assert return_type in ['log_prob', 'prob', 'raw']
        self.model = model
        self.epochs = epochs
        self.lr = lr
        self.__num_hops__ = num_hops
        self.return_type = return_type
        self.log = log
        
    def __set_masks__(self, x, edge_index, init="normal"):
        (N, F), E = x.size(), edge_index.size(1)

        std = 0.1
        self.node_feat_mask = torch.nn.Parameter(torch.randn(N) * 0.1)

        std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * F))
        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std)

        for module in self.model.modules():
            if isinstance(module, MessagePassing):
                module.__explain__ = True
                module.__edge_mask__ = self.edge_mask
        
    def __clear_masks__(self):
        for module in self.model.modules():
            if isinstance(module, MessagePassing):
                module.__explain__ = False
                module.__edge_mask__ = None
                module.__loop_mask__ = None
        self.node_feat_masks = None
        self.edge_mask = None
        self.node_mask = None ########
        module.loop_mask = None
        
    def __loss__(self, node_idx, log_logits, pred_label):


        # node_idx is -1 for explaining graphs
        loss = -log_logits[pred_label.item()] if node_idx == -1 else -log_logits[node_idx, pred_label[node_idx]]

        EPS = self.coeffs['EPS']
        m = self.edge_mask.sigmoid()
        edge_reduce = getattr(torch, self.coeffs['edge_reduction'])
        loss = loss + self.coeffs['edge_size'] * edge_reduce(m)
        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)
        loss = loss + self.coeffs['edge_ent'] * ent.mean()

        m = self.node_feat_mask.sigmoid()
        node_feat_reduce = getattr(torch, self.coeffs['node_feat_reduction'])
        loss = loss + self.coeffs['node_feat_size'] * node_feat_reduce(m)
        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)
        loss = loss + self.coeffs['node_feat_ent'] * ent.mean()

        """
        m = self.node_mask.sigmoid() #################
        node_reduce = getattr(torch, self.coeffs['node_reduction'])
        loss = loss + self.coeffs['node_size'] * node_reduce(m)
        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)
        loss = loss + self.coeffs['node_ent'] * ent.mean()
        """
        
        return loss
  
    def __to_log_prob__(self, x: torch.Tensor) -> torch.Tensor:
        x = x.log_softmax(dim=-1) if self.return_type == 'raw' else x
        x = x.log() if self.return_type == 'prob' else x
        return x
       
    def explain_graph(self, x, edge_index, **kwargs):
        r"""Learns and returns a node feature mask and an edge mask that play a
        crucial role to explain the prediction made by the GNN for a graph.

        Args:
            x (Tensor): The node feature matrix.
            edge_index (LongTensor): The edge indices.
            **kwargs (optional): Additional arguments passed to the GNN module.

        :rtype: (:class:`Tensor`, :class:`Tensor`)
        """

        self.model.eval()
        self.__clear_masks__()

        # all nodes belong to same graph
        batch = torch.zeros(x.shape[0], dtype=int, device=x.device)

        # Get the initial prediction.
        with torch.no_grad():
            out = self.model(x, edge_index, batch, **kwargs)
            log_logits = self.__to_log_prob__(out)
            pred_label = log_logits.argmax(dim=-1)

        self.__set_masks__(x, edge_index)
        self.to(x.device)

        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],
                                     lr=self.lr)

        if self.log:  # pragma: no cover
            pbar = tqdm(total=self.epochs)
            pbar.set_description('Explain graph')

        for epoch in range(1, self.epochs + 1):
            optimizer.zero_grad()
            
            h = x * self.node_feat_mask.view(-1,1).sigmoid()
            out = self.model(h, edge_index, batch, **kwargs)
            log_logits = self.__to_log_prob__(out)
            loss = self.__loss__(-1, log_logits, pred_label)
            loss.backward()
            optimizer.step()

            if self.log:  # pragma: no cover
                pbar.update(1)

        if self.log:  # pragma: no cover
            pbar.close()

        node_feat_mask = self.node_feat_mask.detach().sigmoid()
        edge_mask = self.edge_mask.detach().sigmoid()

        self.__clear_masks__()
        return node_feat_mask, edge_mask


explainer = GNNGraphExplainer(model, epochs=100, lr = 0.0001, return_type='prob')


mydataloader.x.shape,  mydataloader.edge_index


graph_id = 0
node_feat_mask, edge_mask = explainer.explain_graph(torch.unsqueeze(mydataloader.x[graph_id], dim = 0), mydataloader.edge_index)


node_feat_mask
